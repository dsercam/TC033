{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dsercam/TC033/blob/main/A3a_DL_TC5033_embeddings_hw1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font color='darkorange'><b> TC 5033 :: Advanced Machine Learning Methods </b> </font>\n",
        "### <font color='darkgray'><b> Activity 2c: Exploring Transfer Learning with *CIFAR-10*</b></font></br></br>\n",
        "###<font color='darkblue'><b>  Group 44 </b></font>\n",
        "***Dante Rodrigo Serna Camarillo A01182676***</br>\n",
        "***Axel Alejandro Tlatoa Villavicencio A01363351***</br>\n",
        "***Carlos Roberto Torres Ferguson A01215432***</br>\n",
        "***Felipe de Jesús Gastélum Lizárraga A01114918***"
      ],
      "metadata": {
        "id": "g7dAtCZc--0h"
      },
      "id": "g7dAtCZc--0h"
    },
    {
      "cell_type": "markdown",
      "id": "c6142099",
      "metadata": {
        "id": "c6142099"
      },
      "source": [
        "## TC 5033\n",
        "### Word Embeddings\n",
        "\n",
        "<br>\n",
        "\n",
        "#### Activity 3a: Exploring Word Embeddings with GloVe and Numpy\n",
        "<br>\n",
        "\n",
        "- Objective:\n",
        "    - To understand the concept of word embeddings and their significance in Natural Language Processing.\n",
        "    - To learn how to manipulate and visualize high-dimensional data using dimensionality reduction techniques like PCA and t-SNE.\n",
        "    - To gain hands-on experience in implementing word similarity and analogies using GloVe embeddings and Numpy.\n",
        "    \n",
        "<br>\n",
        "\n",
        "- Instructions:\n",
        "    - Download GloVe pre-trained vectors from the provided link in Canvas, the official public project:\n",
        "    Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global Vectors for Word Representation\n",
        "    https://nlp.stanford.edu/data/glove.6B.zip\n",
        "\n",
        "    - Create a dictorionay of the embeddings so that you carry out fast look ups. Save that dictionary e.g. as a serialized file for faster loading in future uses.\n",
        "    \n",
        "    - PCA and t-SNE Visualization: After loading the GloVe embeddings, use Numpy and Sklearn to perform PCA and t-SNE to reduce the dimensionality of the embeddings and visualize them in a 2D or 3D space.\n",
        "\n",
        "    - Word Similarity: Implement a function that takes a word as input and returns the 'n' most similar words based on their embeddings. You should use Numpy to implement this function, using libraries that already implement this function (e.g. Gensim) will result in zero points.\n",
        "\n",
        "    - Word Analogies: Implement a function to solve analogies between words. For example, \"man is to king as woman is to ____\". You should use Numpy to implement this function, using libraries that already implement this function (e.g. Gensim) will result in zero points.\n",
        "\n",
        "    - Submission: This activity is to be submitted in teams of 3 or 4. Only one person should submit the final work, with the full names of all team members included in a markdown cell at the beginning of the notebook.\n",
        "    \n",
        "<br>\n",
        "\n",
        "- Evaluation Criteria:\n",
        "\n",
        "    - Code Quality (40%): Your code should be well-organized, clearly commented, and easy to follow. Use also markdown cells for clarity.\n",
        "    \n",
        "   - Functionality (60%): All functions should work as intended, without errors.\n",
        "       - Visualization of PCA and t-SNE (10% each for a total of 20%)\n",
        "       - Similarity function (20%)\n",
        "       - Analogy function (20%)\n",
        "|\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "329dd09a",
      "metadata": {
        "id": "329dd09a"
      },
      "source": [
        "#### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4af04b9d",
      "metadata": {
        "id": "4af04b9d"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "#import torch\n",
        "#import torch.nn.functional as F\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "import pickle\n",
        "plt.style.use('ggplot')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8712cf42",
      "metadata": {
        "id": "8712cf42"
      },
      "source": [
        "#### Load file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8c3c9d2a",
      "metadata": {
        "id": "8c3c9d2a"
      },
      "outputs": [],
      "source": [
        "# PATH = '/media/pepe/DataUbuntu/Databases/glove_embeddings/glove.6B.200d.txt'\n",
        "PATH = '/glove.6B.50d.txt'\n",
        "emb_dim = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "embeddings_dict = {}\n",
        "with open(\"glove.6B.50d.txt\", 'r') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], \"float32\")\n",
        "        embeddings_dict[word] = vector"
      ],
      "metadata": {
        "id": "Tuvr58SejEbC"
      },
      "id": "Tuvr58SejEbC"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "25a1eae6",
      "metadata": {
        "code_folding": [],
        "id": "25a1eae6"
      },
      "outputs": [],
      "source": [
        "# Create dictionary with embeddings\n",
        "def create_emb_dictionary(path):\n",
        "  #declare dictionary\n",
        "    dictionary = {}\n",
        "  #open file using given path\n",
        "    with open(path, 'r') as f:\n",
        "      for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], \"float32\")\n",
        "        embeddings_dict[word] = vector\n",
        "    return dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "347a0e5e",
      "metadata": {
        "code_folding": [],
        "id": "347a0e5e"
      },
      "outputs": [],
      "source": [
        "# create dictionary\n",
        "embeddings_dict = {}\n",
        "embeddings_dict = create_emb_dictionary(PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "1f01b760",
      "metadata": {
        "code_folding": [
          1
        ],
        "id": "1f01b760"
      },
      "outputs": [],
      "source": [
        "# Serialize\n",
        "with open('embeddings_dict_50D.pkl', 'wb') as f:\n",
        "    pickle.dump(embeddings_dict, f)\n",
        "\n",
        "# Deserialize\n",
        "# with open('embeddings_dict_200D.pkl', 'rb') as f:\n",
        "#     embeddings_dict = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "lLORlWFedDtR",
        "outputId": "cb8651b5-29e9-40b9-c798-2ce3565e7ef2"
      },
      "id": "lLORlWFedDtR",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd0ab9aa",
      "metadata": {
        "id": "fd0ab9aa"
      },
      "source": [
        "#### See some embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "8b0991a9",
      "metadata": {
        "id": "8b0991a9"
      },
      "outputs": [],
      "source": [
        "# Show some\n",
        "def show_n_first_words(path, n_words):\n",
        "        with open(path, 'r') as f:\n",
        "            for i, line in enumerate(f):\n",
        "                print(line.split(), len(line.split()[1:]))\n",
        "                if i>=n_words: break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "a16259ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a16259ec",
        "outputId": "9e41cd8a-fa3a-4fd9-a2b3-206c3b751764"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', '0.418', '0.24968', '-0.41242', '0.1217', '0.34527', '-0.044457', '-0.49688', '-0.17862', '-0.00066023', '-0.6566', '0.27843', '-0.14767', '-0.55677', '0.14658', '-0.0095095', '0.011658', '0.10204', '-0.12792', '-0.8443', '-0.12181', '-0.016801', '-0.33279', '-0.1552', '-0.23131', '-0.19181', '-1.8823', '-0.76746', '0.099051', '-0.42125', '-0.19526', '4.0071', '-0.18594', '-0.52287', '-0.31681', '0.00059213', '0.0074449', '0.17778', '-0.15897', '0.012041', '-0.054223', '-0.29871', '-0.15749', '-0.34758', '-0.045637', '-0.44251', '0.18785', '0.0027849', '-0.18411', '-0.11514', '-0.78581'] 50\n",
            "[',', '0.013441', '0.23682', '-0.16899', '0.40951', '0.63812', '0.47709', '-0.42852', '-0.55641', '-0.364', '-0.23938', '0.13001', '-0.063734', '-0.39575', '-0.48162', '0.23291', '0.090201', '-0.13324', '0.078639', '-0.41634', '-0.15428', '0.10068', '0.48891', '0.31226', '-0.1252', '-0.037512', '-1.5179', '0.12612', '-0.02442', '-0.042961', '-0.28351', '3.5416', '-0.11956', '-0.014533', '-0.1499', '0.21864', '-0.33412', '-0.13872', '0.31806', '0.70358', '0.44858', '-0.080262', '0.63003', '0.32111', '-0.46765', '0.22786', '0.36034', '-0.37818', '-0.56657', '0.044691', '0.30392'] 50\n",
            "['.', '0.15164', '0.30177', '-0.16763', '0.17684', '0.31719', '0.33973', '-0.43478', '-0.31086', '-0.44999', '-0.29486', '0.16608', '0.11963', '-0.41328', '-0.42353', '0.59868', '0.28825', '-0.11547', '-0.041848', '-0.67989', '-0.25063', '0.18472', '0.086876', '0.46582', '0.015035', '0.043474', '-1.4671', '-0.30384', '-0.023441', '0.30589', '-0.21785', '3.746', '0.0042284', '-0.18436', '-0.46209', '0.098329', '-0.11907', '0.23919', '0.1161', '0.41705', '0.056763', '-6.3681e-05', '0.068987', '0.087939', '-0.10285', '-0.13931', '0.22314', '-0.080803', '-0.35652', '0.016413', '0.10216'] 50\n",
            "['of', '0.70853', '0.57088', '-0.4716', '0.18048', '0.54449', '0.72603', '0.18157', '-0.52393', '0.10381', '-0.17566', '0.078852', '-0.36216', '-0.11829', '-0.83336', '0.11917', '-0.16605', '0.061555', '-0.012719', '-0.56623', '0.013616', '0.22851', '-0.14396', '-0.067549', '-0.38157', '-0.23698', '-1.7037', '-0.86692', '-0.26704', '-0.2589', '0.1767', '3.8676', '-0.1613', '-0.13273', '-0.68881', '0.18444', '0.0052464', '-0.33874', '-0.078956', '0.24185', '0.36576', '-0.34727', '0.28483', '0.075693', '-0.062178', '-0.38988', '0.22902', '-0.21617', '-0.22562', '-0.093918', '-0.80375'] 50\n",
            "['to', '0.68047', '-0.039263', '0.30186', '-0.17792', '0.42962', '0.032246', '-0.41376', '0.13228', '-0.29847', '-0.085253', '0.17118', '0.22419', '-0.10046', '-0.43653', '0.33418', '0.67846', '0.057204', '-0.34448', '-0.42785', '-0.43275', '0.55963', '0.10032', '0.18677', '-0.26854', '0.037334', '-2.0932', '0.22171', '-0.39868', '0.20912', '-0.55725', '3.8826', '0.47466', '-0.95658', '-0.37788', '0.20869', '-0.32752', '0.12751', '0.088359', '0.16351', '-0.21634', '-0.094375', '0.018324', '0.21048', '-0.03088', '-0.19722', '0.082279', '-0.09434', '-0.073297', '-0.064699', '-0.26044'] 50\n",
            "['and', '0.26818', '0.14346', '-0.27877', '0.016257', '0.11384', '0.69923', '-0.51332', '-0.47368', '-0.33075', '-0.13834', '0.2702', '0.30938', '-0.45012', '-0.4127', '-0.09932', '0.038085', '0.029749', '0.10076', '-0.25058', '-0.51818', '0.34558', '0.44922', '0.48791', '-0.080866', '-0.10121', '-1.3777', '-0.10866', '-0.23201', '0.012839', '-0.46508', '3.8463', '0.31362', '0.13643', '-0.52244', '0.3302', '0.33707', '-0.35601', '0.32431', '0.12041', '0.3512', '-0.069043', '0.36885', '0.25168', '-0.24517', '0.25381', '0.1367', '-0.31178', '-0.6321', '-0.25028', '-0.38097'] 50\n"
          ]
        }
      ],
      "source": [
        "show_n_first_words(PATH, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff828123",
      "metadata": {
        "id": "ff828123"
      },
      "source": [
        "### Plot some embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d3ffaa4",
      "metadata": {
        "id": "3d3ffaa4"
      },
      "outputs": [],
      "source": [
        "def plot_embeddings(emb_path, words2show, emb_dim, embeddings_dict, func = PCA):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b1b120a",
      "metadata": {
        "id": "9b1b120a"
      },
      "outputs": [],
      "source": [
        "words= ['burger', 'tortilla', 'bread', 'pizza', 'beef', 'steak', 'fries', 'chips',\n",
        "            'argentina', 'mexico', 'spain', 'usa', 'france', 'italy', 'greece', 'china',\n",
        "            'water', 'beer', 'tequila', 'wine', 'whisky', 'brandy', 'vodka', 'coffee', 'tea',\n",
        "            'apple', 'banana', 'orange', 'lemon', 'grapefruit', 'grape', 'strawberry', 'raspberry',\n",
        "            'school', 'work', 'university', 'highschool']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87d33789",
      "metadata": {
        "id": "87d33789"
      },
      "outputs": [],
      "source": [
        "#\n",
        "plot_embeddings(PATH, words, emb_dim, embeddings_dict, PCA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f22bacb4",
      "metadata": {
        "id": "f22bacb4"
      },
      "outputs": [],
      "source": [
        "# t-SNE dimensionality reduction for visualization\n",
        "embeddings = plot_embeddings(PATH, words, emb_dim, embeddings_dict, tSNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8211b7f1",
      "metadata": {
        "id": "8211b7f1"
      },
      "source": [
        "### Let us compute analogies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0003ce18",
      "metadata": {
        "id": "0003ce18"
      },
      "outputs": [],
      "source": [
        "# analogy\n",
        "def analogy(word1, word2, word3, embeddings_dict):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c02ec01",
      "metadata": {
        "id": "9c02ec01"
      },
      "outputs": [],
      "source": [
        "analogy('man', 'king', 'woman', embeddings_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb50e0f7",
      "metadata": {
        "id": "bb50e0f7"
      },
      "outputs": [],
      "source": [
        "# most similar\n",
        "def find_most_similar(word, embeddings_dict, top_n=10):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7946d712",
      "metadata": {
        "id": "7946d712"
      },
      "outputs": [],
      "source": [
        "most_similar = find_most_similar('mexico', embeddings_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b6e0ea1",
      "metadata": {
        "id": "3b6e0ea1"
      },
      "outputs": [],
      "source": [
        "for i, w in enumerate(most_similar, 1):\n",
        "    print(f'{i} ---> {w[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09875cae",
      "metadata": {
        "id": "09875cae"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "985bfda4",
      "metadata": {
        "id": "985bfda4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f06f33c5",
      "metadata": {
        "id": "f06f33c5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05e86fa7",
      "metadata": {
        "id": "05e86fa7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1e1838b",
      "metadata": {
        "id": "e1e1838b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe1a9fad",
      "metadata": {
        "id": "fe1a9fad"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}