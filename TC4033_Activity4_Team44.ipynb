{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dsercam/TC033/blob/main/TC4033_Activity4_Team44.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<font color='darkorange'><b> TC 5033 :: Advanced Machine Learning Methods </b> </font>\n",
        "### <font color='darkgray'><b> Activity 4: Building a Simple LSTM Text Generator using WikiText-2</b></font></br></br>\n",
        "###<font color='darkblue'><b>  Group 44 </b></font>\n",
        "***Dante Rodrigo Serna Camarillo A01182676***</br>\n",
        "***Axel Alejandro Tlatoa Villavicencio A01363351***</br>\n",
        "***Carlos Roberto Torres Ferguson A01215432***</br>\n",
        "***Felipe de Jesús Gastélum Lizárraga A01114918***\n"
      ],
      "metadata": {
        "id": "DwiltKpO5F6R"
      },
      "id": "DwiltKpO5F6R"
    },
    {
      "cell_type": "markdown",
      "id": "037e89c8",
      "metadata": {
        "id": "037e89c8"
      },
      "source": [
        "## TC 5033\n",
        "### Text Generation\n",
        "\n",
        "<br>\n",
        "\n",
        "#### Activity 4: Building a Simple LSTM Text Generator using WikiText-2\n",
        "<br>\n",
        "\n",
        "- Objective:\n",
        "    - Gain a fundamental understanding of Long Short-Term Memory (LSTM) networks.\n",
        "    - Develop hands-on experience with sequence data processing and text generation in PyTorch. Given the simplicity of the model, amount of data, and computer resources, the text you generate will not replace ChatGPT, and results must likely will not make a lot of sense. Its only purpose is academic and to understand the text generation using RNNs.\n",
        "    - Enhance code comprehension and documentation skills by commenting on provided starter code.\n",
        "    \n",
        "<br>\n",
        "\n",
        "- Instructions:\n",
        "    - Code Understanding: Begin by thoroughly reading and understanding the code. Comment each section/block of the provided code to demonstrate your understanding. For this, you are encouraged to add cells with experiments to improve your understanding\n",
        "\n",
        "    - Model Overview: The starter code includes an LSTM model setup for sequence data processing. Familiarize yourself with the model architecture and its components. Once you are familiar with the provided model, feel free to change the model to experiment.\n",
        "\n",
        "    - Training Function: Implement a function to train the LSTM model on the WikiText-2 dataset. This function should feed the training data into the model and perform backpropagation.\n",
        "\n",
        "    - Text Generation Function: Create a function that accepts starting text (seed text) and a specified total number of words to generate. The function should use the trained model to generate a continuation of the input text.\n",
        "\n",
        "    - Code Commenting: Ensure that all the provided starter code is well-commented. Explain the purpose and functionality of each section, indicating your understanding.\n",
        "\n",
        "    - Submission: Submit your Jupyter Notebook with all sections completed and commented. Include a markdown cell with the full names of all contributing team members at the beginning of the notebook.\n",
        "    \n",
        "<br>\n",
        "\n",
        "- Evaluation Criteria:\n",
        "    - Code Commenting (60%): The clarity, accuracy, and thoroughness of comments explaining the provided code. You are suggested to use markdown cells for your explanations.\n",
        "\n",
        "    - Training Function Implementation (20%): The correct implementation of the training function, which should effectively train the model.\n",
        "\n",
        "    - Text Generation Functionality (10%): A working function is provided in comments. You are free to use it as long as you make sure to uderstand it, you may as well improve it as you see fit. The minimum expected is to provide comments for the given function.\n",
        "\n",
        "    - Conclusions (10%): Provide some final remarks specifying the differences you notice between this model and the one used  for classification tasks. Also comment on changes you made to the model, hyperparameters, and any other information you consider relevant. Also, please provide 3 examples of generated texts.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> <font color='darkorange'>If needed, we install the required modules to run on colab </font>"
      ],
      "metadata": {
        "id": "8l8ME65O5edh"
      },
      "id": "8l8ME65O5edh"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-plot\n",
        "!pip install torchdata\n",
        "!pip install tokenizers\n",
        "!pip install portalocker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T06ivXZH5dje",
        "outputId": "6a9dd098-839d-4626-ac56-fbb9e98d5410"
      },
      "id": "T06ivXZH5dje",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-plot in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.11.3)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.3.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->scikit-plot) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.16.0)\n",
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.31.0)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchdata) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchdata) (1.3.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.15.0)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers) (0.19.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.7.22)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (2.8.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "3eb4b117",
      "metadata": {
        "id": "3eb4b117"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "#PyTorch libraries\n",
        "import torch\n",
        "import torchtext\n",
        "from torchtext.datasets import WikiText2\n",
        "# Dataloader library\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.utils.data.dataset import random_split\n",
        "# Libraries to prepare the data\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "# neural layers\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">> _device_ variable that we will use later to compute using the GPU if available, will use the CPU otherwise"
      ],
      "metadata": {
        "id": "mf6EB69a5zkU"
      },
      "id": "mf6EB69a5zkU"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "6d8ff971",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d8ff971",
        "outputId": "70e2a405-b642-4b91-faa4-41cb08a18eb8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Use GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device #see dvice.. we will use GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=\"darkblue\"> **1.1 Instantiate data sets** </font>\n",
        "\n",
        "> We use _WikiText2()_ from the torchtext.datasets to get our 3 datasets</br>\n",
        ">>> *train_dataset* -> first returned object, refers to our training data </br>\n",
        ">>> *val_dataset* -> second returned object, refers to our validation data </br>\n",
        ">>> *test_dataset* -> third returned object, refers to our test data"
      ],
      "metadata": {
        "id": "KSr1qcMwy9Wk"
      },
      "id": "KSr1qcMwy9Wk"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "f3288ce5",
      "metadata": {
        "id": "f3288ce5"
      },
      "outputs": [],
      "source": [
        "train_dataset, val_dataset, test_dataset = WikiText2()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> <font color='darkblue'> Define our tokeniser function, for each line on our iterable text structure, tokenize line </font>"
      ],
      "metadata": {
        "id": "nDJw09njz_US"
      },
      "id": "nDJw09njz_US"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "fc4c7dbd",
      "metadata": {
        "id": "fc4c7dbd"
      },
      "outputs": [],
      "source": [
        "tokeniser = get_tokenizer('basic_english')\n",
        "def yield_tokens(data):\n",
        "    for text in data: #for each line on our data set...\n",
        "        yield tokeniser(text) # tokenize!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> <font color='darkblue'> Build our vocubalary using the tokens found in our training data set. </font><br>\n",
        "> <font color='darkblue'> Add a set of special tokens: </br>\n",
        ">>>  _\\<unk>_ </br>\n",
        ">>>  _\\<pad>_ </br>\n",
        ">>>  _\\<bos>_ </br>\n",
        ">>>  _\\<eos>_ </br>\n",
        "</br>\n",
        "We set our token for unknown _vocabs_ **\\<unk>** at the first position (0), using the *set_defualt_index()* method"
      ],
      "metadata": {
        "id": "nIscH3Pv0mWh"
      },
      "id": "nIscH3Pv0mWh"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "2c2cb068",
      "metadata": {
        "id": "2c2cb068"
      },
      "outputs": [],
      "source": [
        "# Build the vocabulary\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_dataset), specials=[\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"])\n",
        "#set unknown token at position 0\n",
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Defne function to process our data.\n",
        ">> Function receives two parameters, an iterable text data set and the sequence length. </br>\n",
        ">> Tensors are created for the set."
      ],
      "metadata": {
        "id": "BGKaZZZ31GeC"
      },
      "id": "BGKaZZZ31GeC"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "134b832b",
      "metadata": {
        "id": "134b832b"
      },
      "outputs": [],
      "source": [
        "seq_length = 50\n",
        "def data_process(raw_text_iter, seq_length = 50):\n",
        "    #tokenizes the items converting them into tensors, appending them to the data\n",
        "    data = [torch.tensor(vocab(tokeniser(item)), dtype=torch.long) for item in raw_text_iter]\n",
        "    data = torch.cat(tuple(filter(lambda t: t.numel() > 0, data))) #remove empty tensors\n",
        "\n",
        "\n",
        "# returns: reshaped tensor with the input data, where the last incomplete sequence is truncated.\n",
        "# second tensor represents the target data, offset by one step from the input data.\n",
        "    return (data[:-(data.size(0)%seq_length)].view(-1, seq_length),\n",
        "            data[1:-(data.size(0)%seq_length-1)].view(-1, seq_length))\n",
        "\n",
        "# # Create tensors for the training set\n",
        "x_train, y_train = data_process(train_dataset, seq_length)\n",
        "x_val, y_val = data_process(val_dataset, seq_length)\n",
        "x_test, y_test = data_process(test_dataset, seq_length)\n",
        "# processed data is stored in respective tensor variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "4b54c04d",
      "metadata": {
        "id": "4b54c04d"
      },
      "outputs": [],
      "source": [
        "#Creates data tensor for all sets: train, validation and test\n",
        "train_dataset = TensorDataset(x_train, y_train)\n",
        "val_dataset = TensorDataset(x_val, y_val)\n",
        "test_dataset = TensorDataset(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "f4d400fb",
      "metadata": {
        "id": "f4d400fb"
      },
      "outputs": [],
      "source": [
        "batch_size = 64  # choose a batch size that fits your computation resources\n",
        "# Creates batches of data to be used during training, validation, or testing phases\n",
        "# batche size is determined by the value provided to the batch_size varibale\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "59c63b01",
      "metadata": {
        "id": "59c63b01"
      },
      "outputs": [],
      "source": [
        "# Define the LSTM model\n",
        "# Feel free to experiment\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embeddings = nn.Embedding(vocab_size, embed_size) #embedding defined by inpur vocabluary size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True) #long short term memory layer\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size) # linear output layer\n",
        "\n",
        "    def forward(self, text, hidden):\n",
        "        embeddings = self.embeddings(text)\n",
        "        output, hidden = self.lstm(embeddings, hidden)\n",
        "        decoded = self.fc(output)\n",
        "        return decoded, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "\n",
        "        return (torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device),\n",
        "                torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device))\n",
        "\n",
        "\n",
        "\n",
        "vocab_size = len(vocab) # vocabulary size\n",
        "emb_size = 100 # embedding size\n",
        "neurons = 128 # the dimension of the feedforward network model, i.e. # of neurons\n",
        "num_layers = 1 # the number of nn.LSTM layers\n",
        "model = LSTMModel(vocab_size, emb_size, neurons, num_layers) #Instantiate our model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Defined our training function."
      ],
      "metadata": {
        "id": "2ERCTI0d4E--"
      },
      "id": "2ERCTI0d4E--"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "215eabb9",
      "metadata": {
        "id": "215eabb9"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train(model, train_loader, loss_function, optimizer, epochs):\n",
        "    '''\n",
        "    Train the LSTM model on the WikiText-2 dataset.\n",
        "\n",
        "    Parameters:\n",
        "    - model: The LSTM model to be trained.\n",
        "    - train_loader: DataLoader for the training dataset.\n",
        "    - loss_function: The loss function to be used during training.\n",
        "    - optimizer: The optimizer to use for updating model parameters.\n",
        "    - epochs: Number of epochs to train the model.\n",
        "\n",
        "    The training process includes the following steps:\n",
        "    - Loop through the specified number of epochs.\n",
        "    - In each epoch, loop through the training data.\n",
        "    - Zero the gradients before each batch to prevent accumulation.\n",
        "    - Place data (input and target) on the device (GPU/CPU).\n",
        "    - Initialize hidden states for the LSTM.\n",
        "    - Run the model and compute the loss.\n",
        "    - Perform backpropagation and update parameters.\n",
        "    - Print epoch-wise loss and other relevant information.\n",
        "    '''\n",
        "\n",
        "    model = model.to(device=device) # assign the model to the used device, GPU in our case\n",
        "    model.train()  # set the model to training mode\n",
        "\n",
        "    for epoch in range(epochs): #iterate over given epochs\n",
        "        total_loss = 0 #reset epoch loss to zero\n",
        "\n",
        "        for i, (data, targets) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")):\n",
        "            # Place data on the correct device\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "\n",
        "            # Initialize hidden states\n",
        "            hidden = model.init_hidden(data.size(0))\n",
        "\n",
        "            # Gradients to zero\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass: compute predictions and loss\n",
        "            output, _ = model(data, hidden)\n",
        "            loss = loss_function(output.view(-1, vocab_size), targets.view(-1)) #calculate loss using the provided function\n",
        "\n",
        "            # Backward pass: compute gradient and update parameters\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Average loss for the epoch\n",
        "        average_loss = total_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {average_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> To call our training function:\n",
        ">> - Instantiated the loss function to be used, CrossEntropyLoss in this case </br>\n",
        ">> - Set our learning rate to 0.0005 </b>\n",
        ">> - Defined 100 epichs to be used </br>\n",
        ">> - Instantiated an Adam optimizer to provide to the model </br>\n",
        ">>> Called our training function, providing our model, the train dataset, the instantiated loss function and optimizer and the number of epoch to be considered for training.\n"
      ],
      "metadata": {
        "id": "l82_v2bA4I9B"
      },
      "id": "l82_v2bA4I9B"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "aa9c84ce",
      "metadata": {
        "id": "aa9c84ce",
        "outputId": "4881a8e0-a6cb-449f-9985-54f8d2a20635",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100: 100%|██████████| 640/640 [00:26<00:00, 24.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Loss: 7.0163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/100: 100%|██████████| 640/640 [00:26<00:00, 24.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/100, Loss: 6.4059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/100: 100%|██████████| 640/640 [00:26<00:00, 24.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/100, Loss: 6.1596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/100: 100%|██████████| 640/640 [00:25<00:00, 24.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/100, Loss: 5.9856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/100: 100%|██████████| 640/640 [00:26<00:00, 24.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/100, Loss: 5.8606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/100: 100%|██████████| 640/640 [00:26<00:00, 24.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/100, Loss: 5.7622\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/100: 100%|██████████| 640/640 [00:26<00:00, 24.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/100, Loss: 5.6802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/100: 100%|██████████| 640/640 [00:25<00:00, 24.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/100, Loss: 5.6085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/100: 100%|██████████| 640/640 [00:25<00:00, 24.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/100, Loss: 5.5450\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/100: 100%|██████████| 640/640 [00:26<00:00, 24.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100, Loss: 5.4877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/100: 100%|██████████| 640/640 [00:26<00:00, 24.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/100, Loss: 5.4352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/100: 100%|██████████| 640/640 [00:26<00:00, 24.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/100, Loss: 5.3866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/100: 100%|██████████| 640/640 [00:26<00:00, 24.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/100, Loss: 5.3416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/100: 100%|██████████| 640/640 [00:26<00:00, 24.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/100, Loss: 5.2993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/100: 100%|██████████| 640/640 [00:26<00:00, 24.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/100, Loss: 5.2595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/100: 100%|██████████| 640/640 [00:26<00:00, 24.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/100, Loss: 5.2220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/100: 100%|██████████| 640/640 [00:25<00:00, 24.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/100, Loss: 5.1865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/100: 100%|██████████| 640/640 [00:26<00:00, 24.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/100, Loss: 5.1522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/100: 100%|██████████| 640/640 [00:26<00:00, 24.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/100, Loss: 5.1198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/100: 100%|██████████| 640/640 [00:26<00:00, 24.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/100, Loss: 5.0885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/100: 100%|██████████| 640/640 [00:26<00:00, 24.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/100, Loss: 5.0590\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/100: 100%|██████████| 640/640 [00:26<00:00, 24.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/100, Loss: 5.0304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/100: 100%|██████████| 640/640 [00:26<00:00, 24.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/100, Loss: 5.0027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/100: 100%|██████████| 640/640 [00:26<00:00, 24.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/100, Loss: 4.9763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/100: 100%|██████████| 640/640 [00:26<00:00, 24.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/100, Loss: 4.9505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/100: 100%|██████████| 640/640 [00:25<00:00, 24.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/100, Loss: 4.9259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/100: 100%|██████████| 640/640 [00:25<00:00, 24.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/100, Loss: 4.9018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/100: 100%|██████████| 640/640 [00:26<00:00, 24.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/100, Loss: 4.8781\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/100: 100%|██████████| 640/640 [00:25<00:00, 24.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/100, Loss: 4.8557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/100: 100%|██████████| 640/640 [00:25<00:00, 24.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/100, Loss: 4.8333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 31/100: 100%|██████████| 640/640 [00:25<00:00, 24.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/100, Loss: 4.8120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 32/100: 100%|██████████| 640/640 [00:25<00:00, 24.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32/100, Loss: 4.7903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 33/100: 100%|██████████| 640/640 [00:25<00:00, 24.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33/100, Loss: 4.7699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 34/100: 100%|██████████| 640/640 [00:25<00:00, 24.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34/100, Loss: 4.7497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 35/100: 100%|██████████| 640/640 [00:25<00:00, 24.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35/100, Loss: 4.7300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 36/100: 100%|██████████| 640/640 [00:25<00:00, 24.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36/100, Loss: 4.7106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 37/100: 100%|██████████| 640/640 [00:25<00:00, 24.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37/100, Loss: 4.6918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 38/100: 100%|██████████| 640/640 [00:25<00:00, 24.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38/100, Loss: 4.6731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 39/100: 100%|██████████| 640/640 [00:26<00:00, 24.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39/100, Loss: 4.6549\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 40/100: 100%|██████████| 640/640 [00:25<00:00, 24.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40/100, Loss: 4.6372\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 41/100: 100%|██████████| 640/640 [00:25<00:00, 24.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41/100, Loss: 4.6193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 42/100: 100%|██████████| 640/640 [00:25<00:00, 24.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42/100, Loss: 4.6020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 43/100: 100%|██████████| 640/640 [00:25<00:00, 24.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43/100, Loss: 4.5850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 44/100: 100%|██████████| 640/640 [00:25<00:00, 24.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44/100, Loss: 4.5684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 45/100: 100%|██████████| 640/640 [00:25<00:00, 24.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45/100, Loss: 4.5517\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 46/100: 100%|██████████| 640/640 [00:25<00:00, 24.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46/100, Loss: 4.5359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 47/100: 100%|██████████| 640/640 [00:25<00:00, 24.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47/100, Loss: 4.5199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 48/100: 100%|██████████| 640/640 [00:25<00:00, 24.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48/100, Loss: 4.5043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 49/100: 100%|██████████| 640/640 [00:25<00:00, 24.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49/100, Loss: 4.4892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 50/100: 100%|██████████| 640/640 [00:25<00:00, 24.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/100, Loss: 4.4739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 51/100: 100%|██████████| 640/640 [00:25<00:00, 24.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51/100, Loss: 4.4592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 52/100: 100%|██████████| 640/640 [00:26<00:00, 24.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52/100, Loss: 4.4446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 53/100: 100%|██████████| 640/640 [00:25<00:00, 24.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53/100, Loss: 4.4305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 54/100: 100%|██████████| 640/640 [00:25<00:00, 24.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 54/100, Loss: 4.4165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 55/100: 100%|██████████| 640/640 [00:25<00:00, 24.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 55/100, Loss: 4.4026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 56/100: 100%|██████████| 640/640 [00:25<00:00, 24.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56/100, Loss: 4.3891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 57/100: 100%|██████████| 640/640 [00:25<00:00, 24.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57/100, Loss: 4.3761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 58/100: 100%|██████████| 640/640 [00:25<00:00, 24.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58/100, Loss: 4.3629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 59/100: 100%|██████████| 640/640 [00:25<00:00, 24.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59/100, Loss: 4.3497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 60/100: 100%|██████████| 640/640 [00:25<00:00, 24.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60/100, Loss: 4.3373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 61/100: 100%|██████████| 640/640 [00:25<00:00, 24.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61/100, Loss: 4.3250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 62/100: 100%|██████████| 640/640 [00:25<00:00, 24.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 62/100, Loss: 4.3129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 63/100: 100%|██████████| 640/640 [00:25<00:00, 24.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 63/100, Loss: 4.3007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 64/100: 100%|██████████| 640/640 [00:25<00:00, 24.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 64/100, Loss: 4.2890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 65/100: 100%|██████████| 640/640 [00:26<00:00, 24.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 65/100, Loss: 4.2772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 66/100: 100%|██████████| 640/640 [00:25<00:00, 24.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 66/100, Loss: 4.2657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 67/100: 100%|██████████| 640/640 [00:26<00:00, 24.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 67/100, Loss: 4.2544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 68/100: 100%|██████████| 640/640 [00:25<00:00, 24.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 68/100, Loss: 4.2435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 69/100: 100%|██████████| 640/640 [00:25<00:00, 24.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 69/100, Loss: 4.2325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 70/100: 100%|██████████| 640/640 [00:25<00:00, 24.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 70/100, Loss: 4.2216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 71/100: 100%|██████████| 640/640 [00:25<00:00, 24.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 71/100, Loss: 4.2110\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 72/100: 100%|██████████| 640/640 [00:25<00:00, 24.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 72/100, Loss: 4.2004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 73/100: 100%|██████████| 640/640 [00:25<00:00, 24.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 73/100, Loss: 4.1903\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 74/100: 100%|██████████| 640/640 [00:25<00:00, 24.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 74/100, Loss: 4.1802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 75/100: 100%|██████████| 640/640 [00:25<00:00, 24.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 75/100, Loss: 4.1702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 76/100: 100%|██████████| 640/640 [00:25<00:00, 24.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 76/100, Loss: 4.1601\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 77/100: 100%|██████████| 640/640 [00:25<00:00, 24.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 77/100, Loss: 4.1505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 78/100: 100%|██████████| 640/640 [00:25<00:00, 24.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 78/100, Loss: 4.1409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 79/100: 100%|██████████| 640/640 [00:25<00:00, 24.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 79/100, Loss: 4.1313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 80/100: 100%|██████████| 640/640 [00:25<00:00, 24.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 80/100, Loss: 4.1220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 81/100: 100%|██████████| 640/640 [00:25<00:00, 24.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 81/100, Loss: 4.1127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 82/100: 100%|██████████| 640/640 [00:25<00:00, 24.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 82/100, Loss: 4.1035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 83/100: 100%|██████████| 640/640 [00:25<00:00, 24.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 83/100, Loss: 4.0945\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 84/100: 100%|██████████| 640/640 [00:25<00:00, 24.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 84/100, Loss: 4.0856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 85/100: 100%|██████████| 640/640 [00:25<00:00, 24.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 85/100, Loss: 4.0769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 86/100: 100%|██████████| 640/640 [00:25<00:00, 24.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 86/100, Loss: 4.0683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 87/100: 100%|██████████| 640/640 [00:25<00:00, 24.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 87/100, Loss: 4.0596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 88/100: 100%|██████████| 640/640 [00:25<00:00, 24.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 88/100, Loss: 4.0510\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 89/100: 100%|██████████| 640/640 [00:26<00:00, 24.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 89/100, Loss: 4.0427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 90/100: 100%|██████████| 640/640 [00:25<00:00, 24.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 90/100, Loss: 4.0344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 91/100: 100%|██████████| 640/640 [00:25<00:00, 24.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 91/100, Loss: 4.0262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 92/100: 100%|██████████| 640/640 [00:26<00:00, 24.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 92/100, Loss: 4.0182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 93/100: 100%|██████████| 640/640 [00:25<00:00, 24.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 93/100, Loss: 4.0102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 94/100: 100%|██████████| 640/640 [00:25<00:00, 24.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 94/100, Loss: 4.0023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 95/100: 100%|██████████| 640/640 [00:25<00:00, 24.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 95/100, Loss: 3.9946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 96/100: 100%|██████████| 640/640 [00:25<00:00, 24.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 96/100, Loss: 3.9869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 97/100: 100%|██████████| 640/640 [00:25<00:00, 24.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 97/100, Loss: 3.9791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 98/100: 100%|██████████| 640/640 [00:25<00:00, 24.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 98/100, Loss: 3.9715\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 99/100: 100%|██████████| 640/640 [00:25<00:00, 24.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 99/100, Loss: 3.9642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 100/100: 100%|██████████| 640/640 [00:26<00:00, 24.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100/100, Loss: 3.9567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Call the train function\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "lr = 0.0005\n",
        "epochs = 100\n",
        "# Set up the optimizer and loss function for training\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "# Train the model\n",
        "train(model, train_loader, loss_function, optimizer, epochs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "c8667411",
      "metadata": {
        "id": "c8667411",
        "outputId": "40f6a8bf-1b6b-434b-ee35-f829f9e96030",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i like the show medley for a very high and transparent ’ s boyfriend , met it in nice , after listening good hits , she appeared as a review for typical tv week . then made further creative events . i develop that there is one of the atmosphere of that ford ’ s important station — in excess of <unk> , and then taylor and the word sect of clamp , because marquis of the typical known absolute power for semen is that branch of the previous publication period made a play of about 250 under 2 @ . @\n"
          ]
        }
      ],
      "source": [
        "def generate_text(model, start_text, num_words, temperature=1.0):\n",
        "\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    words = tokeniser(start_text)  # Tokenize the starting text/seed.\n",
        "    #words nows contains our starting text in a tokenized structure\n",
        "    hidden = model.init_hidden(1)  # Initialize to hidden state\n",
        "\n",
        "    for i in range(num_words): #loop for text generation, based on input number of words\n",
        "        x = torch.tensor([[vocab[word] for word in words[i:]]], dtype=torch.long, device=device) #for each word/token of our text (first time will use our starter text, will get bigger on each loop)\n",
        "        y_pred, hidden = model(x, hidden) # generate text using our model, based on current text\n",
        "        last_word_logits = y_pred[0][-1] #get the generated words from our prediction\n",
        "        p = (F.softmax(last_word_logits / temperature, dim=0).detach()).to(device='cpu').numpy()\n",
        "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
        "        words.append(vocab.lookup_token(word_index)) # append genrated text\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Generate some text\n",
        "print(generate_text(model, start_text=\"I like\", num_words=100)) #use \" I like \" as an starting text/seed, let the function generate 100 words.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DsoOa4TTEPlK"
      },
      "id": "DsoOa4TTEPlK",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}